{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RIZAL CODES PYSPARK\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from time import time\n",
    "\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import HiveContext, SQLContext\n",
    "import sys, os\n",
    "import shutil\n",
    "import csv\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#initialize the spark session\n",
    "conf = SparkConf().setAppName('TextToTable')\n",
    "#sc = SparkContext(conf=conf)\n",
    "#sqlContext = SQLContext(sc)\n",
    "#sc.setLogLevel('ERROR')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark-getDMP\")\\\n",
    "\t.config(\"spark.some.config.option\", \"some-value\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========  movie_titles_metadata.txt  ====================\n",
      "+-------+--------------------+---------+-----------+------------+--------------------+\n",
      "|movieID|          movieTitle|movieYear|IMDB_Rating|IMDB_n_votes|         movie_genre|\n",
      "+-------+--------------------+---------+-----------+------------+--------------------+\n",
      "|     m0|10 things i hate ...|     1999|       6.90|       62847|['comedy', 'roman...|\n",
      "|     m1|1492: conquest of...|     1992|       6.20|       10421|['adventure', 'bi...|\n",
      "|     m2|          15 minutes|     2001|       6.10|       25854|['action', 'crime...|\n",
      "|     m3|2001: a space ody...|     1968|       8.40|      163227|['adventure', 'my...|\n",
      "|     m4|             48 hrs.|     1982|       6.90|       22289|['action', 'comed...|\n",
      "+-------+--------------------+---------+-----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "movie_titles_metadata.csv : WRITE PANDAS TO CSV DONE!\n",
      "\n",
      "==========  movie_characters_metadata.txt  ====================\n",
      "+-----------+-------------+-------+--------------------+------+----------+\n",
      "|characterID|characterName|movieID|          movieTitle|gender|pos_credit|\n",
      "+-----------+-------------+-------+--------------------+------+----------+\n",
      "|         u0|       BIANCA|     m0|10 things i hate ...|     f|         4|\n",
      "|         u1|        BRUCE|     m0|10 things i hate ...|     ?|         ?|\n",
      "|         u2|      CAMERON|     m0|10 things i hate ...|     m|         3|\n",
      "|         u3|     CHASTITY|     m0|10 things i hate ...|     ?|         ?|\n",
      "|         u4|         JOEY|     m0|10 things i hate ...|     m|         6|\n",
      "+-----------+-------------+-------+--------------------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "movie_characters_metadata.csv : WRITE PANDAS TO CSV DONE!\n",
      "\n",
      "==========  movie_lines.txt  ====================\n",
      "+------+-----------+-------+-------------+------------+\n",
      "|lineID|characterID|movieID|characterName|       utter|\n",
      "+------+-----------+-------+-------------+------------+\n",
      "| L1045|         u0|     m0|       BIANCA|They do not!|\n",
      "| L1044|         u2|     m0|      CAMERON| They do to!|\n",
      "|  L985|         u0|     m0|       BIANCA|  I hope so.|\n",
      "|  L984|         u2|     m0|      CAMERON|   She okay?|\n",
      "|  L925|         u0|     m0|       BIANCA|   Let's go.|\n",
      "+------+-----------+-------+-------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "movie_lines.csv : WRITE PANDAS TO CSV DONE!\n",
      "\n",
      "==========  movie_conversations.txt  ====================\n",
      "+-------------+-------------+-------+--------------------+\n",
      "|characterID_1|characterID_2|movieID|          utter_list|\n",
      "+-------------+-------------+-------+--------------------+\n",
      "|           u0|           u2|     m0|['L194', 'L195', ...|\n",
      "|           u0|           u2|     m0|    ['L198', 'L199']|\n",
      "|           u0|           u2|     m0|['L200', 'L201', ...|\n",
      "|           u0|           u2|     m0|['L204', 'L205', ...|\n",
      "|           u0|           u2|     m0|    ['L207', 'L208']|\n",
      "+-------------+-------------+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "movie_conversations.csv : WRITE PANDAS TO CSV DONE!\n",
      "\n",
      "==========  raw_script_urls.txt  ====================\n",
      "+-------+--------------------+--------------------+\n",
      "|movieID|          movieTitle|                 url|\n",
      "+-------+--------------------+--------------------+\n",
      "|     m0|10 things i hate ...|http://www.dailys...|\n",
      "|     m1|1492: conquest of...|http://www.hundla...|\n",
      "|     m2|          15 minutes|http://www.dailys...|\n",
      "|     m3|2001: a space ody...|http://www.scifis...|\n",
      "|     m4|             48 hrs.|http://www.awesom...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "raw_script_urls.csv : WRITE PANDAS TO CSV DONE!\n"
     ]
    }
   ],
   "source": [
    "#================== read txt & save to csv ================\n",
    "\n",
    "\n",
    "def readmytxt(filename,separator,mylist):\n",
    "    \n",
    "    print'\\n========== ',filename,' ===================='\n",
    "    myrdd = sc.textFile(filename)\\\n",
    "            .map(lambda l: l.split(separator))\n",
    "    df = sqlContext.createDataFrame(myrdd)\n",
    "    \n",
    "    for i in range(len(df.schema.names)):      \n",
    "        df = df.withColumnRenamed(df.schema.names[i],mylist[i])\n",
    "\n",
    "    df.show(5)\n",
    "    \n",
    "    \n",
    "   \n",
    "    #write databricks csv \n",
    "    myfoldername = filename.split('.')[0]\n",
    "    \"\"\"\n",
    "    if os.path.isdir(myfoldername):shutil.rmtree(myfoldername)\n",
    "    df.coalesce(1)\\\n",
    "    .write\\\n",
    "    .format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .save(myfoldername)\n",
    "    print 'databricks:write csv done!'\n",
    "    \n",
    "     \"\"\"\n",
    "    \n",
    "    #write pandas csv \n",
    "    csvfilename = myfoldername +'.csv'\n",
    "    df_pd = df.toPandas()\n",
    "    df_pd.to_csv(csvfilename, quoting=csv.QUOTE_NONNUMERIC, index = False, encoding = 'utf-8')\n",
    "    print csvfilename,': WRITE PANDAS TO CSV DONE!'\n",
    "    \n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "mv_title_meta = readmytxt(\"movie_titles_metadata.txt\",\n",
    "                 \" +++$+++ \",\n",
    "                 ['movieID','movieTitle','movieYear','IMDB_Rating','IMDB_n_votes','movie_genre'])\n",
    "\n",
    "\n",
    "\n",
    "mv_char_meta = readmytxt(\"movie_characters_metadata.txt\",\n",
    "                 \" +++$+++ \",\n",
    "                 ['characterID','characterName','movieID','movieTitle','gender','pos_credit'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mv_line = readmytxt(\"movie_lines.txt\",\n",
    "                 \" +++$+++ \",\n",
    "                 ['lineID','characterID','movieID','characterName','utter'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mv_conv = readmytxt(\"movie_conversations.txt\",\n",
    "                 \" +++$+++ \",\n",
    "                 ['characterID_1','characterID_2','movieID','utter_list'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "raw_scr_url = readmytxt(\"raw_script_urls.txt\",\n",
    "                 \" +++$+++ \",\n",
    "                 ['movieID','movieTitle','url'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- utter: string (nullable = true)\n",
      "\n",
      "+--------------------+\n",
      "|               utter|\n",
      "+--------------------+\n",
      "|         they do not|\n",
      "|          they do to|\n",
      "|           i hope so|\n",
      "|            she okay|\n",
      "|             lets go|\n",
      "|                 wow|\n",
      "|okay  youre gonna...|\n",
      "|                  no|\n",
      "|im kidding  you k...|\n",
      "|like my fear of w...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#=================  pyspark ==================\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, split\n",
    "\n",
    "def clean_text(c):\n",
    "  c = lower(c)\n",
    "  c = regexp_replace(c, \"^rt \", \"\")\n",
    "  c = regexp_replace(c, \"(https?\\://)\\S+\", \"\")\n",
    "  c = regexp_replace(c, \"[^a-zA-Z0-9\\\\s]\", \"\")\n",
    "  #c = split(c, \"\\\\s+\") tokenization...\n",
    "  return c\n",
    "\n",
    "clean_text_df = mv_line.select(clean_text(col(\"utter\")).alias(\"utter\"))\n",
    "\n",
    "clean_text_df.printSchema()\n",
    "clean_text_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vector: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+--------------------+\n",
      "|              vector|\n",
      "+--------------------+\n",
      "|     [they, do, not]|\n",
      "|      [they, do, to]|\n",
      "|       [i, hope, so]|\n",
      "|         [she, okay]|\n",
      "|          [lets, go]|\n",
      "|               [wow]|\n",
      "|[okay, , youre, g...|\n",
      "|                [no]|\n",
      "|[im, kidding, , y...|\n",
      "|[like, my, fear, ...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"utter\", outputCol=\"vector\")\n",
    "vector_df = tokenizer.transform(clean_text_df).select(\"vector\")\n",
    "\n",
    "vector_df.printSchema()\n",
    "vector_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- vector_no_stopw: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+--------------------+\n",
      "|     vector_no_stopw|\n",
      "+--------------------+\n",
      "|                  []|\n",
      "|                  []|\n",
      "|              [hope]|\n",
      "|              [okay]|\n",
      "|          [lets, go]|\n",
      "|               [wow]|\n",
      "|[okay, , youre, g...|\n",
      "|                  []|\n",
      "|[im, kidding, , k...|\n",
      "|[like, fear, wear...|\n",
      "|              [real]|\n",
      "|       [good, stuff]|\n",
      "|[figured, youd, g...|\n",
      "|[thank, god, , he...|\n",
      "|[, endless, blond...|\n",
      "|              [crap]|\n",
      "|      [listen, crap]|\n",
      "|                  []|\n",
      "|[guillermo, says,...|\n",
      "|   [always, selfish]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "# Define a list of stop words or use default list\n",
    "remover = StopWordsRemover()\n",
    "stopwords = remover.getStopWords() \n",
    "\n",
    "\n",
    "remover.setInputCol(\"vector\")\n",
    "remover.setOutputCol(\"vector_no_stopw\")\n",
    "\n",
    "# Transform existing dataframe with the StopWordsRemover\n",
    "vector_no_stopw_df = remover.transform(vector_df).select(\"vector_no_stopw\")\n",
    "\n",
    "# Display\n",
    "vector_no_stopw_df.printSchema()\n",
    "vector_no_stopw_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thank\n",
      "it\n",
      "proverbi\n",
      "unexpect\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "# Import stemmer library\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "# Instantiate stemmer object\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Quick test of the stemming function\n",
    "tokens = [\"thanks\", \"its\", \"proverbially\", \"unexpected\", \"running\"]\n",
    "for t in tokens:\n",
    "  print(stemmer.stem(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unigrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n",
      "+--------------------+\n",
      "|            unigrams|\n",
      "+--------------------+\n",
      "|                  []|\n",
      "|                  []|\n",
      "|              [hope]|\n",
      "|              [okay]|\n",
      "|               [let]|\n",
      "|               [wow]|\n",
      "|[okay, your, gonn...|\n",
      "|                  []|\n",
      "|[kid, know, somet...|\n",
      "|[like, fear, wear...|\n",
      "|              [real]|\n",
      "|       [good, stuff]|\n",
      "|[figur, youd, get...|\n",
      "|[thank, god, hear...|\n",
      "|[endless, blond, ...|\n",
      "|              [crap]|\n",
      "|      [listen, crap]|\n",
      "|                  []|\n",
      "|[guillermo, say, ...|\n",
      "|    [alway, selfish]|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create stemmer python function\n",
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = stemmer.stem(t)\n",
    "        if len(t_stem) > 2:\n",
    "            out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "\n",
    "\n",
    "\n",
    "# Create user defined function for stemming with return type Array<String>\n",
    "from pyspark.sql.types import *\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create new df with vectors containing the stemmed tokens \n",
    "vector_stemmed_df = (\n",
    "    vector_no_stopw_df\n",
    "        .withColumn(\"vector_stemmed\", stemmer_udf(\"vector_no_stopw\"))\n",
    "        .select(\"vector_stemmed\")\n",
    "  )\n",
    "\n",
    "# Rename df and column for clarity\n",
    "production_df = vector_stemmed_df.select(col(\"vector_stemmed\").alias(\"unigrams\"))\n",
    "\n",
    "# Display\n",
    "production_df.printSchema()\n",
    "production_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unigrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- bigrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n",
      "+--------------------+--------------------+\n",
      "|            unigrams|             bigrams|\n",
      "+--------------------+--------------------+\n",
      "|                  []|                  []|\n",
      "|                  []|                  []|\n",
      "|              [hope]|                  []|\n",
      "|              [okay]|                  []|\n",
      "|               [let]|                  []|\n",
      "|               [wow]|                  []|\n",
      "|[okay, your, gonn...|[okay your, your ...|\n",
      "|                  []|                  []|\n",
      "|[kid, know, somet...|[kid know, know s...|\n",
      "|[like, fear, wear...|[like fear, fear ...|\n",
      "|              [real]|                  []|\n",
      "|       [good, stuff]|        [good stuff]|\n",
      "|[figur, youd, get...|[figur youd, youd...|\n",
      "|[thank, god, hear...|[thank god, god h...|\n",
      "|[endless, blond, ...|[endless blond, b...|\n",
      "|              [crap]|                  []|\n",
      "|      [listen, crap]|       [listen crap]|\n",
      "|                  []|                  []|\n",
      "|[guillermo, say, ...|[guillermo say, s...|\n",
      "|    [alway, selfish]|     [alway selfish]|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "# Define NGram transformer\n",
    "ngram = NGram(n=2, inputCol=\"unigrams\", outputCol=\"bigrams\")\n",
    "\n",
    "# Create bigram_df as a transform of unigram_df using NGram tranformer\n",
    "production_df = ngram.transform(production_df)\n",
    "\n",
    "# Display\n",
    "production_df.printSchema()\n",
    "production_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- unigrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- bigrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- trigrams: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      "\n",
      "+--------------------+--------------------+--------------------+\n",
      "|            unigrams|             bigrams|            trigrams|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|                  []|                  []|                  []|\n",
      "|                  []|                  []|                  []|\n",
      "|              [hope]|                  []|                  []|\n",
      "|              [okay]|                  []|                  []|\n",
      "|               [let]|                  []|                  []|\n",
      "|               [wow]|                  []|                  []|\n",
      "|[okay, your, gonn...|[okay your, your ...|[okay your gonna,...|\n",
      "|                  []|                  []|                  []|\n",
      "|[kid, know, somet...|[kid know, know s...|[kid know sometim...|\n",
      "|[like, fear, wear...|[like fear, fear ...|[like fear wear, ...|\n",
      "|              [real]|                  []|                  []|\n",
      "|       [good, stuff]|        [good stuff]|                  []|\n",
      "|[figur, youd, get...|[figur youd, youd...|[figur youd get, ...|\n",
      "|[thank, god, hear...|[thank god, god h...|[thank god hear, ...|\n",
      "|[endless, blond, ...|[endless blond, b...|[endless blond ba...|\n",
      "|              [crap]|                  []|                  []|\n",
      "|      [listen, crap]|       [listen crap]|                  []|\n",
      "|                  []|                  []|                  []|\n",
      "|[guillermo, say, ...|[guillermo say, s...|[guillermo say li...|\n",
      "|    [alway, selfish]|     [alway selfish]|                  []|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import NGram\n",
    "\n",
    "# Define NGram transformer\n",
    "ngram = NGram(n=3, inputCol=\"unigrams\", outputCol=\"trigrams\")\n",
    "\n",
    "# Create bigram_df as a transform of unigram_df using NGram tranformer\n",
    "production_df = ngram.transform(production_df)\n",
    "\n",
    "# Display\n",
    "production_df.printSchema()\n",
    "production_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+-------+-------------+--------------------+---+\n",
      "|lineID|characterID|movieID|characterName|               utter| id|\n",
      "+------+-----------+-------+-------------+--------------------+---+\n",
      "| L1045|         u0|     m0|       BIANCA|        They do not!|  0|\n",
      "| L1044|         u2|     m0|      CAMERON|         They do to!|  1|\n",
      "|  L985|         u0|     m0|       BIANCA|          I hope so.|  2|\n",
      "|  L984|         u2|     m0|      CAMERON|           She okay?|  3|\n",
      "|  L925|         u0|     m0|       BIANCA|           Let's go.|  4|\n",
      "|  L924|         u2|     m0|      CAMERON|                 Wow|  5|\n",
      "|  L872|         u0|     m0|       BIANCA|Okay -- you're go...|  6|\n",
      "|  L871|         u2|     m0|      CAMERON|                  No|  7|\n",
      "|  L870|         u0|     m0|       BIANCA|I'm kidding.  You...|  8|\n",
      "|  L869|         u0|     m0|       BIANCA|Like my fear of w...|  9|\n",
      "|  L868|         u2|     m0|      CAMERON|     The \"real you\".| 10|\n",
      "|  L867|         u0|     m0|       BIANCA|    What good stuff?| 11|\n",
      "|  L866|         u2|     m0|      CAMERON|I figured you'd g...| 12|\n",
      "|  L865|         u2|     m0|      CAMERON|Thank God!  If I ...| 13|\n",
      "|  L864|         u0|     m0|       BIANCA|Me.  This endless...| 14|\n",
      "|  L863|         u2|     m0|      CAMERON|          What crap?| 15|\n",
      "|  L862|         u0|     m0|       BIANCA|do you listen to ...| 16|\n",
      "|  L861|         u2|     m0|      CAMERON|               No...| 17|\n",
      "|  L860|         u0|     m0|       BIANCA|Then Guillermo sa...| 18|\n",
      "|  L699|         u2|     m0|      CAMERON|You always been t...| 19|\n",
      "+------+-----------+-------+-------------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "|            unigrams|             bigrams|            trigrams| id|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "|                  []|                  []|                  []|  0|\n",
      "|                  []|                  []|                  []|  1|\n",
      "|              [hope]|                  []|                  []|  2|\n",
      "|              [okay]|                  []|                  []|  3|\n",
      "|               [let]|                  []|                  []|  4|\n",
      "|               [wow]|                  []|                  []|  5|\n",
      "|[okay, your, gonn...|[okay your, your ...|[okay your gonna,...|  6|\n",
      "|                  []|                  []|                  []|  7|\n",
      "|[kid, know, somet...|[kid know, know s...|[kid know sometim...|  8|\n",
      "|[like, fear, wear...|[like fear, fear ...|[like fear wear, ...|  9|\n",
      "|              [real]|                  []|                  []| 10|\n",
      "|       [good, stuff]|        [good stuff]|                  []| 11|\n",
      "|[figur, youd, get...|[figur youd, youd...|[figur youd get, ...| 12|\n",
      "|[thank, god, hear...|[thank god, god h...|[thank god hear, ...| 13|\n",
      "|[endless, blond, ...|[endless blond, b...|[endless blond ba...| 14|\n",
      "|              [crap]|                  []|                  []| 15|\n",
      "|      [listen, crap]|       [listen crap]|                  []| 16|\n",
      "|                  []|                  []|                  []| 17|\n",
      "|[guillermo, say, ...|[guillermo say, s...|[guillermo say li...| 18|\n",
      "|    [alway, selfish]|     [alway selfish]|                  []| 19|\n",
      "+--------------------+--------------------+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+--------------------+--------------------+------+-----------+-------+-------------+--------------------+\n",
      "|            unigrams|             bigrams|            trigrams|lineID|characterID|movieID|characterName|               utter|\n",
      "+--------------------+--------------------+--------------------+------+-----------+-------+-------------+--------------------+\n",
      "|               [ton]|                  []|                  []|  L663|         u0|     m0|       BIANCA|                Tons|\n",
      "|    [know, chastiti]|     [know chastiti]|                  []|  L577|         u0|     m0|       BIANCA|  You know Chastity?|\n",
      "|                  []|                  []|                  []|  L767|         u5|     m0|          KAT|       You 're so --|\n",
      "|               [way]|                  []|                  []| L3475|        u30|     m2|         EMIL|        No.  No way.|\n",
      "|[realli, said, mi...|[realli said, sai...|[realli said migh...| L3979|        u60|     m3|        POOLE|Not really. They ...|\n",
      "|[hal, unless, fol...|[hal unless, unle...|[hal unless follo...| L4363|        u50|     m3|       BOWMAN|Hal, unless you f...|\n",
      "|[quit, frankli, r...|[quit frankli, fr...|[quit frankli rel...| L3768|        u61|     m3|      SMYSLOV|Quite frankly, we...|\n",
      "|[live, die, let, ...|[live die, die le...|[live die let, di...| L5325|        u67|     m4|        CATES|He can live or di...|\n",
      "|[yeah, cop, prett...|[yeah cop, cop pr...|[yeah cop pretti,...| L5074|        u67|     m4|        CATES|Yeah, most cops a...|\n",
      "|[take, prison, ba...|[take prison, pri...|[take prison back...| L5245|        u67|     m4|        CATES|I'm taking my pri...|\n",
      "|              [yeah]|                  []|                  []| L4637|        u67|     m4|        CATES|               Yeah.|\n",
      "|  [dont, mess, much]|[dont mess, mess ...|    [dont mess much]| L5117|        u71|     m4|      HAMMOND|Don't mess with m...|\n",
      "|[your, probabl, a...|[your probabl, pr...|[your probabl ang...| L6168|        u78|     m5|    CORNELIUS|You're probably v...|\n",
      "|       [she, except]|        [she except]|                  []| L5649|        u78|     m5|    CORNELIUS|She's an exception..|\n",
      "|[sometim, cant, k...|[sometim cant, ca...|[sometim cant kno...| L6431|       u114|     m6|       WELLES|Sometimes you can...|\n",
      "|        [fuck, want]|         [fuck want]|                  []| L7037|       u105|     m6|        EDDIE|What the fuck do ...|\n",
      "|[mom, taught, lit...|[mom taught, taug...|[mom taught littl...| L8054|       u115|     m7|        ALICE|My mom taught me ...|\n",
      "|                  []|                  []|                  []| L8670|       u123|     m8|        ALICE|Where are you going?|\n",
      "|[gotta, hear, won...|[gotta hear, hear...|[gotta hear wont,...|L12727|       u154|    m10|         WADE|But you gotta hea...|\n",
      "|                  []|                  []|                  []|L16888|       u166|    m11|    KORSHUNOV|       Who did this?|\n",
      "+--------------------+--------------------+--------------------+------+-----------+-------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "\n",
    "mv_line = mv_line.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "production_df = production_df.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "mv_line.show()\n",
    "\n",
    "production_df.show()\n",
    "\n",
    "mv_line = production_df.join(mv_line, \"id\", \"outer\").drop(\"id\")\n",
    "\n",
    "mv_line.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": WRITE PANDAS TO CSV DONE!\n"
     ]
    }
   ],
   "source": [
    "df_pd = mv_line.toPandas()\n",
    "df_pd.to_csv('mv_line_final.csv', quoting=csv.QUOTE_NONNUMERIC, index = False, encoding = 'utf-8')\n",
    "print ': WRITE PANDAS TO CSV DONE!'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
